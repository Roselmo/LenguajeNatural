{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSUoHE5d2X2T"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Universidad EAFIT \n",
        "# 2025-1\n",
        "# SI7003 - NLP - Lecture 07\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo 1: Creación de un Agente LLM en Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (0.3.45)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
            "  Downloading aiohttp-3.11.14-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (0.3.16)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-community) (2.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-core) (2.10.3)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading multidict-6.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
            "  Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (69 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.14-cp312-cp312-macosx_11_0_arm64.whl (456 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.5.0-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading multidict-6.2.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
            "Downloading propcache-0.3.0-cp312-cp312-macosx_11_0_arm64.whl (45 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading yarl-1.18.3-cp312-cp312-macosx_11_0_arm64.whl (92 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.5.0 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 multidict-6.2.0 mypy-extensions-1.0.0 propcache-0.3.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0 yarl-1.18.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting openai\n",
            "  Using cached openai-1.66.5-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\n",
            "  Using cached langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.3.16-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain) (2.10.3)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading sqlalchemy-2.0.39-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>4 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from faiss-cpu) (2.0.1)\n",
            "Requirement already satisfied: packaging in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.45->langchain)\n",
            "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.1)\n",
            "Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
            "Using cached openai-1.66.5-py3-none-any.whl (571 kB)\n",
            "Downloading faiss_cpu-1.10.0-cp312-cp312-macosx_11_0_arm64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (319 kB)\n",
            "Using cached langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
            "Using cached langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
            "Using cached langsmith-0.3.16-py3-none-any.whl (344 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading sqlalchemy-2.0.39-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.15-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Installing collected packages: tenacity, SQLAlchemy, sniffio, orjson, jiter, h11, faiss-cpu, requests-toolbelt, httpcore, anyio, httpx, openai, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed SQLAlchemy-2.0.39 anyio-4.9.0 faiss-cpu-1.10.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 langchain-0.3.21 langchain-core-0.3.45 langchain-text-splitters-0.3.7 langsmith-0.3.16 openai-1.66.5 orjson-3.10.15 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0\n"
          ]
        }
      ],
      "source": [
        "# instalar dependencias\n",
        "!pip install langchain openai faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Configuración de modelo LLM\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m llm = \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Memoria del agente\u001b[39;00m\n\u001b[32m     12\u001b[39m memory = ConversationBufferMemory(memory_key=\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m, return_messages=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pydantic/main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ],
      "source": [
        "# Configuración del Agente con LangChain\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Configuración de modelo LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
        "\n",
        "# Memoria del agente\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Herramienta personalizada (Ejemplo: búsqueda en Wikipedia)\n",
        "def search_wikipedia(query):\n",
        "    from langchain.utilities import WikipediaAPIWrapper\n",
        "    wiki = WikipediaAPIWrapper()\n",
        "    return wiki.run(query)\n",
        "\n",
        "tool = Tool(\n",
        "    name=\"Wikipedia\",\n",
        "    func=search_wikipedia,\n",
        "    description=\"Busca información en Wikipedia.\"\n",
        ")\n",
        "\n",
        "# Inicialización del agente\n",
        "agent = initialize_agent(\n",
        "    tools=[tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Ejemplo de interacción\n",
        "print(agent.run(\"¿Quién fue Alan Turing?\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo 2: Agente con Razonamiento y Planificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-search-results\n",
            "  Using cached google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: requests in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrespuertagonzalez/miniconda3/lib/python3.12/site-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32063 sha256=2757cb2130e70e22231c6b20800a027c51845eb378c4be656b05ec019d82deb7\n",
            "  Stored in directory: /Users/andrespuertagonzalez/Library/Caches/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for SerpAPIWrapper\n  Value error, Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SystemMessage\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tools\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m tools = \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mserpapi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Agregar herramientas como búsqueda web\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Prompt de agente con planificación\u001b[39;00m\n\u001b[32m     29\u001b[39m system_message = SystemMessage(\n\u001b[32m     30\u001b[39m     content=\u001b[33m\"\u001b[39m\u001b[33mEres un agente de IA que descompone problemas complejos en pasos más pequeños y ejecuta acciones.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/langchain_community/agent_toolkits/load_tools.py:753\u001b[39m, in \u001b[36mload_tools\u001b[39m\u001b[34m(tool_names, llm, callbacks, allow_dangerous_tools, **kwargs)\u001b[39m\n\u001b[32m    751\u001b[39m     _get_tool_func, extra_keys = _EXTRA_OPTIONAL_TOOLS[name]\n\u001b[32m    752\u001b[39m     sub_kwargs = {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m extra_keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     tool = \u001b[43m_get_tool_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msub_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     tools.append(tool)\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/langchain_community/agent_toolkits/load_tools.py:387\u001b[39m, in \u001b[36m_get_serpapi\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_get_serpapi\u001b[39m(**kwargs: Any) -> BaseTool:\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Tool(\n\u001b[32m    385\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mSearch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    386\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33mA search engine. Useful for when you need to answer questions about current events. Input should be a search query.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         func=\u001b[43mSerpAPIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.run,\n\u001b[32m    388\u001b[39m         coroutine=SerpAPIWrapper(**kwargs).arun,\n\u001b[32m    389\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pydantic/main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for SerpAPIWrapper\n  Value error, Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass `serpapi_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results\n",
        "\n",
        "# Este agente puede recibir objetivos y descomponerlos en tareas usando un marco de planificación.\n",
        "\n",
        "# se requiere la API KEY de SerpAPI - https://serpapi.\n",
        "\n",
        "# realice el registro en línea, tiene 100 busquedas gratuitas al men, uso no comercial\n",
        "\n",
        "# crera la variable con el valor SERPAPI_API_KEY\n",
        "\n",
        "# en el bash shell:\n",
        "\n",
        "# bash$ set SERPAPI_API_KEY=123...232\n",
        "# bash$ export SERPAPI_API_KEY\n",
        "# bash$ echo $SERPAPI_API_KEY\n",
        "# 123...232\n",
        "\n",
        "#import os\n",
        "#os.environ[\"SERPAPI_API_KEY\"] = \"TU_CLAVE_API\"\n",
        "\n",
        "\n",
        "\n",
        "from langchain.schema import SystemMessage\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools([\"serpapi\"])  # Agregar herramientas como búsqueda web\n",
        "\n",
        "# Prompt de agente con planificación\n",
        "system_message = SystemMessage(\n",
        "    content=\"Eres un agente de IA que descompone problemas complejos en pasos más pequeños y ejecuta acciones.\"\n",
        ")\n",
        "\n",
        "# Crear agente con planificación\n",
        "agent_executor = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Ejecutar agente\n",
        "result = agent_executor.run(\"Encuentra las últimas noticias sobre inteligencia artificial.\")\n",
        "print(result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "# Intended for Jupyter notebooks where there's an existing event loop\n",
        "result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")  # type: ignore[top-level-await]  # noqa: F704\n",
        "print(result.final_output)\n",
        "\n",
        "# Code within code loops,\n",
        "# Infinite mirrors reflect—\n",
        "# Logic folds on self."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# funciona como un programa aparte: ejemplo.py\n",
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "# Intended for Jupyter notebooks where there's an existing event loop\n",
        "result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")  # type: ignore[top-level-await]  # noqa: F704\n",
        "print(result.final_output)\n",
        "\n",
        "# Code within code loops,\n",
        "# Infinite mirrors reflect—\n",
        "# Logic folds on self."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "from agents import Agent, Runner\n",
        "\n",
        "print(dir(Runner))  # Verifica qué métodos están disponibles en Runner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ejecución asincrónica dentro de notebook:\n",
        "\n",
        "import nest_asyncio\n",
        "#import asyncio\n",
        "from agents import Agent, Runner\n",
        "\n",
        "nest_asyncio.apply()  # Permite usar asyncio en Jupyter sin conflictos\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
        "    print(result.final_output)\n",
        "\n",
        "await main()  # Ejecutar directamente en Jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from agents import Agent, Runner\n",
        "\n",
        "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
        "\n",
        "async def main():\n",
        "    result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
        "    print(result.final_output)\n",
        "\n",
        "asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo 3 - instalación basica de llamaindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install llama-index-llms-huggingface-api llama-index-embeddings-huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "\n",
        "llm = HuggingFaceInferenceAPI(\n",
        "    model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        "    token=\"hf_xxx\",\n",
        ")\n",
        "\n",
        "llm.complete(\"Hello, how are you?\")\n",
        "# I am good, how can I help you today?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab1-nltk.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
